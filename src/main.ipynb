{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    " # Music Genre Classification\n",
    " #### By Jack Kelly, Dylan Kiratli, Luke Gries, and Zad Khan\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Main File for our testing for the project\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 15:52:54.655220: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Keras\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:52:53.643788Z",
     "end_time": "2023-04-23T15:52:56.455918Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing code from another strategy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 files belonging to 10 classes.\n",
      "Using 800 files for training.\n",
      "Found 999 files belonging to 10 classes.\n",
      "Using 199 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 15:52:56.766861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "img_height = 288\n",
    "img_width = 432\n",
    "batch_size = 10\n",
    "data_dir = \"../data/Images_Original\"\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels = \"inferred\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle = True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels = \"inferred\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle = True,\n",
    "    batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:52:56.654528Z",
     "end_time": "2023-04-23T15:52:56.848908Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recent Strategy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Let's add some functions to generate the full spectrogram and generate segments of the spectrogram so we have more data to train on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_melspectrogram(wav_file_path, length=30, duration_of_segments=5, overlap=False, duration_of_step=1):\n",
    "\n",
    "    \"\"\"\n",
    "    Get mel spectrogram for a given wav file and divide it into parts.\n",
    "\n",
    "    :param wav_file_path: Path to the source wav file\n",
    "    :param length: length in seconds of the source audio file. Defaults to 30.\n",
    "    :param duration_of_segments: duration of segments in seconds. number of segments = length/duration_of_segments. Defaults to 5.\n",
    "    :param overlap: boolean determining whether slices of audio file will be overlapped or distinct. Defaults to False\n",
    "    :param duration_of_step: step size from the beginning of one segment to the beginning of the next. Defaults to 1 second. Unused if overlap is False.\n",
    "    :return: Mel spectrogram of the source wav file. Segments will be saved to a file and it's path will be printed.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(wav_file_path, sr=None, duration=length)\n",
    "    melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "    # Determine the number of samples in the duration of segments\n",
    "    samples_per_segment = sr * duration_of_segments\n",
    "\n",
    "    if overlap:\n",
    "        samples_per_step = sr * duration_of_step\n",
    "        num_segments= length // duration_of_step - duration_of_segments + 1\n",
    "    else:\n",
    "        num_segments = length // duration_of_segments\n",
    "\n",
    "    # Loop through the audio signal and extract the segments\n",
    "    for i in range(num_segments):\n",
    "        # Get the start and end indices of the segment\n",
    "        if overlap:\n",
    "            start = i * samples_per_step\n",
    "        else:\n",
    "            start = i * samples_per_segment\n",
    "        end = start + samples_per_segment\n",
    "\n",
    "        # Extract the segment from the audio signal\n",
    "        segment = y[start:end]\n",
    "\n",
    "        # Compute the mel spectrogram of the segment\n",
    "        mel_spec_segment = librosa.feature.melspectrogram(y=segment, sr=sr)\n",
    "\n",
    "        # sample name\n",
    "        sample_name = wav_file_path.replace(\"../data/genres_original/\",\"\").replace(\".wav\",\"\")\n",
    "\n",
    "        # path to save samples to\n",
    "        sample_name = f'{sample_name.split(\"/\")[0]}/npy/{sample_name.split(\"/\")[1]}'\n",
    "\n",
    "        # splitting files which contain overlapped vs distinct segments\n",
    "        if overlap:\n",
    "            directory = \"overlap\"\n",
    "        else:\n",
    "            directory = \"distinct\"\n",
    "\n",
    "\n",
    "        save_path = f'../data/mel_spec_samples/{directory}/{sample_name}_{i}.npy'\n",
    "        # Save the mel spectrogram to a file\n",
    "        np.save(save_path, mel_spec_segment)\n",
    "        \"\"\" print(f'Saved segment /mel_spec_samples/{directory}/{sample_name}_{i}.npy') \"\"\"\n",
    "\n",
    "    return melspectrogram\n",
    "\n",
    "\n",
    "def plot_melspectrogram(melspectrogram):\n",
    "    \"\"\"\n",
    "    Plot mel spectrogram using pyplot to visualize the data. Works for both full spectrogram and segments.\n",
    "\n",
    "    :param melspectrogram: np.array of mel spectrogram generated using librosa.feature.melspectrogram()\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(librosa.power_to_db(melspectrogram, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:00.050909Z",
     "end_time": "2023-04-23T15:53:00.059306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# test segmentation of audio file\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "for test_genre in genres:\n",
    "    # Make the directories to avoid file not found errors\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{test_genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{test_genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{test_genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{test_genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{test_genre}/png', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{test_genre}/png', exist_ok=True)\n",
    "\n",
    "    # Filename to test functions\n",
    "    for i in range(0,10):\n",
    "        sample_number = \"\"\n",
    "        if i < 10:\n",
    "            sample_number = f'0{i}'\n",
    "        else:\n",
    "            sample_number = f'{i}'\n",
    "        test_filename = f'../data/genres_original/{test_genre}/{test_genre}.000{sample_number}.wav'\n",
    "\n",
    "        # Test the main get_melspectrogram function to generate the full audio spectrogram of a given file, and save segments of itself to files\n",
    "        mel_spectrogram = get_melspectrogram(test_filename, length=30, duration_of_segments=5)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:01.780911Z",
     "end_time": "2023-04-23T15:53:08.645250Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run this if you are getting 'Directory Not Found' errors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Run this if you are getting 'Directory Not Found' errors\n",
    "\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "for genre in genres:\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{genre}/png', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{genre}/png', exist_ok=True)\n",
    "    os.makedirs\n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:08.646300Z",
     "end_time": "2023-04-23T15:53:08.652879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now let's generate the images from the mel spectrogram segments we generated above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to generate images from mel spectrograms for a given genre\n",
    "def generate_images_for_genre(genre, num_samples=6, overlap=False):\n",
    "    \"\"\"\n",
    "    Generate images from mel spectrogram segments for a given genre and save them to the same directory as the segments.\n",
    "\n",
    "    :param genre: string of genre to generate images for\n",
    "    :param num_samples: number of samples. Defaults to 6.\n",
    "    :param overlap: boolean determining whether slices of audio file will be overlapped or distinct. Defaults to False. Needed here for directory purposes.\n",
    "    :return: False if error, True if successful\n",
    "    \"\"\"\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "    if genre not in genres:\n",
    "        print(f'Genre \\\"{genre}\\\" not in list of genres')\n",
    "        return False\n",
    "    for j in range(0,100):\n",
    "        sample_number = \"\"\n",
    "        if j < 10:\n",
    "            sample_number = f'0{j}'\n",
    "        else:\n",
    "            sample_number = f'{j}'\n",
    "\n",
    "        # splitting files which contain overlapped vs distinct segments\n",
    "        if overlap:\n",
    "            directory = \"overlap\"\n",
    "        else:\n",
    "            directory = \"distinct\"\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            mel_segment = np.load(f'../data/mel_spec_samples/{directory}/{genre}/npy/{genre}.000{sample_number}_{i}.npy')\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            librosa.display.specshow(librosa.power_to_db(mel_segment, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f'{genre}.00000_{i}.npy')\n",
    "            plt.tight_layout()\n",
    "            save_name = f'../data/mel_spec_samples/{directory}/{genre}/png/{genre}.000{sample_number}_{i}.png'\n",
    "            plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            print(f'Saved image: {save_name}')\n",
    "\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:48:32.373579Z",
     "end_time": "2023-04-23T13:48:32.388970Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test that bad boy\n",
    "\n",
    "#### This will take a minute or two to run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_images_for_genre('classical', num_samples=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's generate images for all genre samples\n",
    "\n",
    "#### This will take a while to run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test segmentation of audio file\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "\n",
    "for test_genre in genres:\n",
    "\n",
    "    for i in range(0,100):\n",
    "        sample_number = \"\"\n",
    "        if i < 10:\n",
    "            sample_number = f'0{i}'\n",
    "        else:\n",
    "            sample_number = f'{i}'\n",
    "\n",
    "\n",
    "\n",
    "        test_filename = f'../data/genres_original/{test_genre}/{test_genre}.000{sample_number}.wav'\n",
    "\n",
    "\n",
    "        # Test the main get_melspectrogram function to generate the full audio spectrogram of a given file, and save segments of itself to files\n",
    "        mel_spectrogram = get_melspectrogram(test_filename, length=30, duration_of_segments=5, overlap=True, duration_of_step=1)\n",
    "\n",
    "        if mel_spectrogram.shape != (128, 1292):\n",
    "            print (\"bug\")\n",
    "            print(mel_spectrogram.shape)\n",
    "            print(f'../data/genres_original/{test_genre}/{test_genre}.000{sample_number}.wav')\n",
    "        # Generate images for all the genre segments\n",
    "        # COMMENTED CUS WE DONT NEED RN\n",
    "        # generate_images_for_genre(test_genre, num_samples=6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:55:52.491453Z",
     "end_time": "2023-04-23T13:58:30.368746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param overlap: boolean determining whether slices of audio file will be overlapped or distinct. Defaults to False. Needed here for directory purposes.\n",
    "\"\"\"\n",
    "def get_data_and_labels(overlap=False):\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # splitting files which contain overlapped vs distinct segments\n",
    "    if overlap:\n",
    "        directory = \"overlap\"\n",
    "    else:\n",
    "        directory = \"distinct\"\n",
    "\n",
    "    print(f'Extracting...')\n",
    "\n",
    "    for genre in genres:\n",
    "        print(f'Extracting {genre}')\n",
    "        for file in os.listdir(f'../data/mel_spec_samples/{directory}/{genre}/npy'):\n",
    "\n",
    "            # Extracting Mel Spectrogram feature\n",
    "            # Use normalize_melspectrogram to get normalized mel spectrogram features to fit model\n",
    "            melspectrogram = np.load(f'../data/mel_spec_samples/{directory}/{genre}/npy/{file}')\n",
    "\n",
    "            if melspectrogram.shape[1] != 216:\n",
    "\n",
    "                print(\"Bug\")\n",
    "                print(file)\n",
    "                print(melspectrogram.shape[0])\n",
    "                print(melspectrogram.shape[1])\n",
    "\n",
    "            if melspectrogram.shape[0] != 128:\n",
    "\n",
    "                print(\"Bug\")\n",
    "                print(file)\n",
    "                print(melspectrogram.shape[0])\n",
    "                print(melspectrogram.shape[1])\n",
    "\n",
    "            # Extracting Label\n",
    "            label = genres.index(genre)\n",
    "\n",
    "            # Appending features and labels\n",
    "            data.append(melspectrogram)\n",
    "            labels.append(label)\n",
    "\n",
    "    print('Finished extracting features and labels for all genres')\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:17.778712Z",
     "end_time": "2023-04-23T15:53:17.797099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting...\n",
      "Extracting blues\n",
      "Extracting classical\n",
      "Extracting country\n",
      "Extracting disco\n",
      "Extracting hiphop\n",
      "Extracting jazz\n",
      "Extracting metal\n",
      "Extracting pop\n",
      "Extracting reggae\n",
      "Extracting rock\n",
      "Finished extracting features and labels for all genres\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = get_data_and_labels(overlap=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:20.162696Z",
     "end_time": "2023-04-23T15:53:28.694599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def train_test_split(x_data, y_data):\n",
    "    x_shuffled, y_shuffled = shuffle(x_data, y_data, random_state=0)\n",
    "    split_size = int(0.8 * len(x_shuffled))\n",
    "    x_train = x_shuffled[:split_size]\n",
    "    y_train = y_shuffled[:split_size]\n",
    "    x_test = x_shuffled[split_size:]\n",
    "    y_test = y_shuffled[split_size:]\n",
    "    return x_train, y_train, x_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:29.868958Z",
     "end_time": "2023-04-23T15:53:29.877940Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# See how it went broski"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(x_data, y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:33:25.182875Z",
     "end_time": "2023-04-23T22:33:25.201636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:33:25.620343Z",
     "end_time": "2023-04-23T22:34:11.194433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:34:26.585914Z",
     "end_time": "2023-04-23T22:34:26.604230Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:34:34.428779Z",
     "end_time": "2023-04-23T22:34:34.434124Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "net = Sequential([\n",
    "    keras.Input(shape=(128, 216, 1)),\n",
    "    Conv2D(28, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer =tf.keras.regularizers.l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(14, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer =tf.keras.regularizers.l2( l=0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation=\"softmax\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:34:35.629605Z",
     "end_time": "2023-04-23T22:34:35.657973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2080/2080 [==============================] - 93s 44ms/step - loss: 2.1856 - accuracy: 0.4108\n",
      "Epoch 2/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 1.3240 - accuracy: 0.5780\n",
      "Epoch 3/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 1.0900 - accuracy: 0.6564\n",
      "Epoch 4/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.9751 - accuracy: 0.6910\n",
      "Epoch 5/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.9037 - accuracy: 0.7146\n",
      "Epoch 6/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.8164 - accuracy: 0.7464\n",
      "Epoch 7/20\n",
      "2080/2080 [==============================] - 94s 45ms/step - loss: 0.7868 - accuracy: 0.7558\n",
      "Epoch 8/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.7376 - accuracy: 0.7734\n",
      "Epoch 9/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.6999 - accuracy: 0.7823\n",
      "Epoch 10/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.6860 - accuracy: 0.7925\n",
      "Epoch 11/20\n",
      "2080/2080 [==============================] - 95s 46ms/step - loss: 0.6573 - accuracy: 0.7992\n",
      "Epoch 12/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.6396 - accuracy: 0.8056\n",
      "Epoch 13/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.6246 - accuracy: 0.8112\n",
      "Epoch 14/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.6062 - accuracy: 0.8160\n",
      "Epoch 15/20\n",
      "2080/2080 [==============================] - 91s 44ms/step - loss: 0.5966 - accuracy: 0.8207\n",
      "Epoch 16/20\n",
      "2080/2080 [==============================] - 92s 44ms/step - loss: 0.5861 - accuracy: 0.8242\n",
      "Epoch 17/20\n",
      "2080/2080 [==============================] - 92s 44ms/step - loss: 0.5668 - accuracy: 0.8305\n",
      "Epoch 18/20\n",
      "2080/2080 [==============================] - 92s 44ms/step - loss: 0.5611 - accuracy: 0.8308\n",
      "Epoch 19/20\n",
      "2080/2080 [==============================] - 92s 44ms/step - loss: 0.5565 - accuracy: 0.8339\n",
      "Epoch 20/20\n",
      "2080/2080 [==============================] - 92s 44ms/step - loss: 0.5407 - accuracy: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fd2109558b0>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "net.fit(train_dataset, batch_size=BATCH_SIZE, epochs=20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T22:34:36.734996Z",
     "end_time": "2023-04-23T23:05:10.178075Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Normalize the Data so that it has 0 mean and unit variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/520 [==============================] - 7s 12ms/step - loss: 0.8704 - accuracy: 0.7381\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.8704332709312439, 0.73807692527771]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:06:10.879990Z",
     "end_time": "2023-04-23T23:06:17.498076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load saved spectrogram from .npy files and plot them in subplots\n",
    "test_filename = f'../data/mel_spec_samples/blues/blues.00000_0.npy'\n",
    "var = np.load(test_filename)\n",
    "\n",
    "plot_melspectrogram(var)\n",
    "\n",
    "# Generate normalized mel spectrogram\n",
    "mel_spectrograms_normalized = normalize_melspectrogram('../data/mel_spec_samples/blues/blues.00000_0.npy')\n",
    "\n",
    "print(f'shape: {mel_spectrograms_normalized.shape}')\n",
    "# Plot the first mel spectrogram in the normalized data as a line plot\n",
    "plt.plot(mel_spectrograms_normalized[0].flatten())\n",
    "plt.title('Normalized Mel Spectrogram')\n",
    "plt.xlabel('Mel spectrogram bin')\n",
    "plt.ylabel('Normalized value')\n",
    "plt.show()\n",
    "\n",
    "# Plot the first mel spectrogram in the normalized data as a line plot\n",
    "plt.plot(var.flatten())\n",
    "plt.title('Original Mel Spectrogram')\n",
    "plt.xlabel('Mel spectrogram bin')\n",
    "plt.ylabel('Normalized value')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
