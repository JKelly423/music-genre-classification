{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    " # Music Genre Classification\n",
    " #### By Jack Kelly, Dylan Kiratli, Luke Gries, and Zad Khan\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Main File for our testing for the project\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 22:05:32.472898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Keras\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:05:31.648553Z",
     "end_time": "2023-04-24T22:05:34.088069Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing code from another strategy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 files belonging to 10 classes.\n",
      "Using 800 files for training.\n",
      "Found 999 files belonging to 10 classes.\n",
      "Using 199 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 15:52:56.766861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset\n",
    "img_height = 288\n",
    "img_width = 432\n",
    "batch_size = 10\n",
    "data_dir = \"../data/Images_Original\"\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels = \"inferred\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle = True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels = \"inferred\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle = True,\n",
    "    batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:52:56.654528Z",
     "end_time": "2023-04-23T15:52:56.848908Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recent Strategy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Let's add some functions to generate the full spectrogram and generate segments of the spectrogram so we have more data to train on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_melspectrogram(wav_file_path, length=30, duration_of_segments=5, overlap=False, duration_of_step=1):\n",
    "\n",
    "    \"\"\"\n",
    "    Get mel spectrogram for a given wav file and divide it into parts.\n",
    "\n",
    "    :param wav_file_path: Path to the source wav file\n",
    "    :param length: length in seconds of the source audio file. Defaults to 30.\n",
    "    :param duration_of_segments: duration of segments in seconds. number of segments = length/duration_of_segments. Defaults to 5.\n",
    "    :param overlap: boolean determining whether slices of audio file will be overlapped or distinct. Defaults to False\n",
    "    :param duration_of_step: step size from the beginning of one segment to the beginning of the next. Defaults to 1 second. Unused if overlap is False.\n",
    "    :return: Mel spectrogram of the source wav file. Segments will be saved to a file and it's path will be printed.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(wav_file_path, sr=None, duration=length)\n",
    "    melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "    # Determine the number of samples in the duration of segments\n",
    "    samples_per_segment = sr * duration_of_segments\n",
    "\n",
    "    if overlap:\n",
    "        samples_per_step = sr * duration_of_step\n",
    "        num_segments= length // duration_of_step - duration_of_segments + 1\n",
    "    else:\n",
    "        num_segments = length // duration_of_segments\n",
    "\n",
    "    # Loop through the audio signal and extract the segments\n",
    "    for i in range(num_segments):\n",
    "        # Get the start and end indices of the segment\n",
    "        if overlap:\n",
    "            start = i * samples_per_step\n",
    "        else:\n",
    "            start = i * samples_per_segment\n",
    "        end = start + samples_per_segment\n",
    "\n",
    "        # Extract the segment from the audio signal\n",
    "        segment = y[start:end]\n",
    "\n",
    "        # Compute the mel spectrogram of the segment\n",
    "        mel_spec_segment = librosa.feature.melspectrogram(y=segment, sr=sr)\n",
    "\n",
    "        # sample name\n",
    "        sample_name = wav_file_path.replace(\"../data/genres_original/\",\"\").replace(\".wav\",\"\")\n",
    "\n",
    "        # path to save samples to\n",
    "        sample_name = f'{sample_name.split(\"/\")[0]}/npy/{sample_name.split(\"/\")[1]}'\n",
    "\n",
    "        # splitting files which contain overlapped vs distinct segments\n",
    "        if overlap:\n",
    "            directory = \"overlap\"\n",
    "        else:\n",
    "            directory = \"distinct\"\n",
    "\n",
    "\n",
    "        save_path = f'../data/mel_spec_samples/{directory}/{sample_name}_{i}.npy'\n",
    "        # Save the mel spectrogram to a file\n",
    "        np.save(save_path, mel_spec_segment)\n",
    "        \"\"\" print(f'Saved segment /mel_spec_samples/{directory}/{sample_name}_{i}.npy') \"\"\"\n",
    "\n",
    "    return melspectrogram\n",
    "\n",
    "\n",
    "def plot_melspectrogram(melspectrogram):\n",
    "    \"\"\"\n",
    "    Plot mel spectrogram using pyplot to visualize the data. Works for both full spectrogram and segments.\n",
    "\n",
    "    :param melspectrogram: np.array of mel spectrogram generated using librosa.feature.melspectrogram()\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(librosa.power_to_db(melspectrogram, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T19:31:29.213119Z",
     "end_time": "2023-04-24T19:31:29.226270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# test segmentation of audio file\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "for test_genre in genres:\n",
    "    # Make the directories to avoid file not found errors\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{test_genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{test_genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{test_genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{test_genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{test_genre}/png', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{test_genre}/png', exist_ok=True)\n",
    "\n",
    "    # Filename to test functions\n",
    "    for i in range(0,10):\n",
    "        sample_number = \"\"\n",
    "        if i < 10:\n",
    "            sample_number = f'0{i}'\n",
    "        else:\n",
    "            sample_number = f'{i}'\n",
    "        test_filename = f'../data/genres_original/{test_genre}/{test_genre}.000{sample_number}.wav'\n",
    "\n",
    "        # Test the main get_melspectrogram function to generate the full audio spectrogram of a given file, and save segments of itself to files\n",
    "        mel_spectrogram = get_melspectrogram(test_filename, length=30, duration_of_segments=5)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:01.780911Z",
     "end_time": "2023-04-23T15:53:08.645250Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run this if you are getting 'Directory Not Found' errors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Run this if you are getting 'Directory Not Found' errors\n",
    "\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "for genre in genres:\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{genre}', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{genre}/npy', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/distinct/{genre}/png', exist_ok=True)\n",
    "    os.makedirs(f'../data/mel_spec_samples/overlap/{genre}/png', exist_ok=True)\n",
    "    os.makedirs\n",
    "\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T15:53:08.646300Z",
     "end_time": "2023-04-23T15:53:08.652879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now let's generate the images from the mel spectrogram segments we generated above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to generate images from mel spectrograms for a given genre\n",
    "def generate_images_for_genre(genre, num_samples=6, overlap=False):\n",
    "    \"\"\"\n",
    "    Generate images from mel spectrogram segments for a given genre and save them to the same directory as the segments.\n",
    "\n",
    "    :param genre: string of genre to generate images for\n",
    "    :param num_samples: number of samples. Defaults to 6.\n",
    "    :param overlap: boolean determining whether slices of audio file will be overlapped or distinct. Defaults to False. Needed here for directory purposes.\n",
    "    :return: False if error, True if successful\n",
    "    \"\"\"\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "    if genre not in genres:\n",
    "        print(f'Genre \\\"{genre}\\\" not in list of genres')\n",
    "        return False\n",
    "    for j in range(0,100):\n",
    "        sample_number = \"\"\n",
    "        if j < 10:\n",
    "            sample_number = f'0{j}'\n",
    "        else:\n",
    "            sample_number = f'{j}'\n",
    "\n",
    "        # splitting files which contain overlapped vs distinct segments\n",
    "        if overlap:\n",
    "            directory = \"overlap\"\n",
    "        else:\n",
    "            directory = \"distinct\"\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            mel_segment = np.load(f'../data/mel_spec_samples/{directory}/{genre}/npy/{genre}.000{sample_number}_{i}.npy')\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            librosa.display.specshow(librosa.power_to_db(mel_segment, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f'{genre}.00000_{i}.npy')\n",
    "            plt.tight_layout()\n",
    "            save_name = f'../data/mel_spec_samples/{directory}/{genre}/png/{genre}.000{sample_number}_{i}.png'\n",
    "            plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            print(f'Saved image: {save_name}')\n",
    "\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:48:32.373579Z",
     "end_time": "2023-04-23T13:48:32.388970Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test that bad boy\n",
    "\n",
    "#### This will take a minute or two to run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_images_for_genre('classical', num_samples=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's generate images for all genre samples\n",
    "\n",
    "#### This will take a while to run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test segmentation of audio file\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "\n",
    "for test_genre in genres:\n",
    "\n",
    "    for i in range(0,100):\n",
    "        sample_number = \"\"\n",
    "        if i < 10:\n",
    "            sample_number = f'0{i}'\n",
    "        else:\n",
    "            sample_number = f'{i}'\n",
    "\n",
    "\n",
    "\n",
    "        test_filename = f'../data/genres_original/{test_genre}/{test_genre}.000{sample_number}.wav'\n",
    "\n",
    "\n",
    "        # Test the main get_melspectrogram function to generate the full audio spectrogram of a given file, and save segments of itself to files\n",
    "        mel_spectrogram = get_melspectrogram(test_filename, length=30, duration_of_segments=5, overlap=True, duration_of_step=1)\n",
    "\n",
    "        if mel_spectrogram.shape != (128, 1292):\n",
    "            print (\"bug\")\n",
    "            print(mel_spectrogram.shape)\n",
    "            print(f'../data/genres_original/{test_genre}/{test_genre}.000{sample_number}.wav')\n",
    "        # Generate images for all the genre segments\n",
    "        # COMMENTED CUS WE DONT NEED RN\n",
    "        # generate_images_for_genre(test_genre, num_samples=6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T13:55:52.491453Z",
     "end_time": "2023-04-23T13:58:30.368746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":param overlap: boolean determining whether slices of audio file will be overlapped or distinct. Defaults to False. Needed here for directory purposes.\n",
    "\"\"\"\n",
    "def get_data_and_labels(overlap=False):\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # splitting files which contain overlapped vs distinct segments\n",
    "    if overlap:\n",
    "        directory = \"overlap\"\n",
    "    else:\n",
    "        directory = \"distinct\"\n",
    "\n",
    "    print(f'Extracting...')\n",
    "\n",
    "    for genre in genres:\n",
    "        print(f'Extracting {genre}')\n",
    "        for file in os.listdir(f'../data/mel_spec_samples/{directory}/{genre}/npy'):\n",
    "\n",
    "            # Extracting Mel Spectrogram feature\n",
    "            # Use normalize_melspectrogram to get normalized mel spectrogram features to fit model\n",
    "            melspectrogram = np.load(f'../data/mel_spec_samples/{directory}/{genre}/npy/{file}')\n",
    "\n",
    "            if melspectrogram.shape[1] != 216:\n",
    "\n",
    "                print(\"Bug\")\n",
    "                print(file)\n",
    "                print(melspectrogram.shape[0])\n",
    "                print(melspectrogram.shape[1])\n",
    "\n",
    "            if melspectrogram.shape[0] != 128:\n",
    "\n",
    "                print(\"Bug\")\n",
    "                print(file)\n",
    "                print(melspectrogram.shape[0])\n",
    "                print(melspectrogram.shape[1])\n",
    "\n",
    "            # Extracting Label\n",
    "            label = genres.index(genre)\n",
    "\n",
    "            # Appending features and labels\n",
    "            data.append(melspectrogram)\n",
    "            labels.append(label)\n",
    "\n",
    "    print('Finished extracting features and labels for all genres')\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T22:05:59.732396Z",
     "end_time": "2023-04-24T22:05:59.736792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting...\n",
      "Extracting blues\n",
      "Extracting classical\n",
      "Extracting country\n",
      "Extracting disco\n",
      "Extracting hiphop\n",
      "Extracting jazz\n",
      "Extracting metal\n",
      "Extracting pop\n",
      "Extracting reggae\n",
      "Extracting rock\n",
      "Finished extracting features and labels for all genres\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T01:25:15.234308Z",
     "end_time": "2023-04-24T01:25:26.505521Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RUN CODE FROM HERE ONCE DATA CREATED**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting...\n",
      "Extracting blues\n",
      "Extracting classical\n",
      "Extracting country\n",
      "Extracting disco\n",
      "Extracting hiphop\n",
      "Extracting jazz\n",
      "Extracting metal\n",
      "Extracting pop\n",
      "Extracting reggae\n",
      "Extracting rock\n",
      "Finished extracting features and labels for all genres\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_data, y_data = get_data_and_labels(overlap=True)\n",
    "\n",
    "def preprocess_mel_spectrogram(mel_spectrogram, normalize=True):\n",
    "    \"\"\"\n",
    "    Preprocesses a mel spectrogram for use in a neural network.\n",
    "\n",
    "    Args:\n",
    "        mel_spectrogram (numpy array): Mel spectrogram to be preprocessed.\n",
    "        normalize (bool, optional): Whether to normalize the mel spectrogram. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Preprocessed mel spectrogram.\n",
    "    \"\"\"\n",
    "    # Convert to decibels\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    mel_spectrogram = np.float32(mel_spectrogram)\n",
    "\n",
    "    # Normalize if specified\n",
    "    if normalize:\n",
    "        # Normalize to [0, 1]\n",
    "        mel_spectrogram = (mel_spectrogram - np.min(mel_spectrogram)) / (np.max(mel_spectrogram) - np.min(mel_spectrogram))\n",
    "\n",
    "    # Convert to 3D array with an additional channel dimension\n",
    "    mel_spectrogram = np.expand_dims(mel_spectrogram, axis=-1)\n",
    "\n",
    "    return mel_spectrogram\n",
    "\n",
    "\n",
    "def train_test_split(x_data, y_data):\n",
    "    print(np.max(x_data))\n",
    "    print(np.min(x_data))\n",
    "\n",
    "    for i in range(0, len(x_data)):\n",
    "        x_data[i] = preprocess_mel_spectrogram(x_data[i])\n",
    "\n",
    "    x_shuffled, y_shuffled = shuffle(x_data, y_data, random_state=0)\n",
    "    test_percentage = 0.2\n",
    "    test_split = int(1-test_percentage * len(x_shuffled))\n",
    "    x_test = x_shuffled[test_split:]\n",
    "    y_test = y_shuffled[test_split:]\n",
    "    #val_percentage = 0.2\n",
    "    #val_split = int(1-test_percentage-val_percentage * len(x_shuffled))\n",
    "    #x_val = x_shuffled[val_split:test_split]\n",
    "    #y_val = y_shuffled[val_split:test_split]\n",
    "\n",
    "    x_train = x_shuffled[:test_split]\n",
    "    y_train = y_shuffled[:test_split]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test#, x_val, y_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:06:50.442445Z",
     "end_time": "2023-04-25T09:07:01.678561Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# See how it went broski"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10813.572\n",
      "0.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(x_data, y_data)\n",
    "\n",
    "print(np.max(x_train))\n",
    "\n",
    "print(np.min(x_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:07:11.134729Z",
     "end_time": "2023-04-25T09:07:19.805363Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Takes ~ 6 minutes to run on my machine**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset created\n",
      "test dataset created\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "print(\"train dataset created\")\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "print(\"test dataset created\")\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:07:23.225754Z",
     "end_time": "2023-04-25T09:14:08.462054Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RUN CODE FROM HERE FOR TRAINING**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "b_train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "b_test_dataset = test_dataset.batch(BATCH_SIZE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:17:56.690671Z",
     "end_time": "2023-04-25T09:17:56.802874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2081/2081 [==============================] - 80s 38ms/step - loss: 1.3583 - accuracy: 0.6072 - val_loss: 0.8952 - val_accuracy: 0.7215\n",
      "Epoch 2/10\n",
      "2081/2081 [==============================] - 76s 36ms/step - loss: 0.6516 - accuracy: 0.8038 - val_loss: 0.8215 - val_accuracy: 0.7357\n",
      "Epoch 3/10\n",
      "2081/2081 [==============================] - 80s 38ms/step - loss: 0.4333 - accuracy: 0.8791 - val_loss: 0.8685 - val_accuracy: 0.7251\n",
      "Epoch 4/10\n",
      "2081/2081 [==============================] - 78s 37ms/step - loss: 0.3336 - accuracy: 0.9108 - val_loss: 1.0855 - val_accuracy: 0.6903\n",
      "Epoch 5/10\n",
      "2081/2081 [==============================] - 78s 38ms/step - loss: 0.2726 - accuracy: 0.9327 - val_loss: 0.9783 - val_accuracy: 0.7465\n"
     ]
    }
   ],
   "source": [
    "net = Sequential([\n",
    "    keras.Input(shape=(128, 216, 1)),\n",
    "    Dropout(0.1),\n",
    "    Conv2D(16, kernel_size=(5, 5), activation=\"relu\", kernel_regularizer=L2(0.1)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation=\"softmax\")])\n",
    "\n",
    "net.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, mode='min', restore_best_weights=True)\n",
    "\n",
    "history = net.fit(b_train_dataset, batch_size=BATCH_SIZE, verbose=1, epochs=10, callbacks=[earlyStopping], validation_data = b_test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:17:57.928790Z",
     "end_time": "2023-04-25T09:24:29.815880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:24:53.723791Z",
     "end_time": "2023-04-25T09:24:53.728108Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "` # Normalize the Data so that it has 0 mean and unit variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/520 [==============================] - 4s 7ms/step - loss: 0.8215 - accuracy: 0.7357\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.8215222358703613, 0.7357184290885925]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(b_test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T09:26:01.736762Z",
     "end_time": "2023-04-25T09:26:05.610904Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load saved spectrogram from .npy files and plot them in subplots\n",
    "test_filename = f'../data/mel_spec_samples/blues/blues.00000_0.npy'\n",
    "var = np.load(test_filename)\n",
    "\n",
    "plot_melspectrogram(var)\n",
    "\n",
    "# Generate normalized mel spectrogram\n",
    "mel_spectrograms_normalized = normalize_melspectrogram('../data/mel_spec_samples/blues/blues.00000_0.npy')\n",
    "\n",
    "print(f'shape: {mel_spectrograms_normalized.shape}')\n",
    "# Plot the first mel spectrogram in the normalized data as a line plot\n",
    "plt.plot(mel_spectrograms_normalized[0].flatten())\n",
    "plt.title('Normalized Mel Spectrogram')\n",
    "plt.xlabel('Mel spectrogram bin')\n",
    "plt.ylabel('Normalized value')\n",
    "plt.show()\n",
    "\n",
    "# Plot the first mel spectrogram in the normalized data as a line plot\n",
    "plt.plot(var.flatten())\n",
    "plt.title('Original Mel Spectrogram')\n",
    "plt.xlabel('Mel spectrogram bin')\n",
    "plt.ylabel('Normalized value')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
